{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = pd.read_csv(\"../data/train_transactions.csv\",index_col = 0)\n",
    "fraud = pd.read_csv(\"../data/train_fraudsters.csv\",index_col = 0)\n",
    "users = pd.read_csv(\"../data/train_users.csv\",index_col = 0)\n",
    "transaction.Fraud = transaction.Fraud.apply(lambda x: 0 if x== \"0\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Line Model\n",
    "\n",
    "Randomly Guess if it's Fraud or not\n",
    "<BR>\n",
    "Simple Logistic Model base on transaction Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19733462343519903"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "Guess_Fraud =  transaction.Fraud.apply(lambda x: 1 if np.random.uniform(0,1)>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.50      0.66    674108\n",
      "           1       0.02      0.50      0.04     14543\n",
      "\n",
      "    accuracy                           0.50    688651\n",
      "   macro avg       0.50      0.50      0.35    688651\n",
      "weighted avg       0.96      0.50      0.65    688651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(transaction.Fraud,Guess_Fraud))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With random guess, there is a 2% chance of being correct on predicting Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transaction.AMOUNT\n",
    "y = transaction.Fraud\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log =  LogisticRegression()\n",
    "log.fit(np.array(X_train).reshape(-1,1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    202233\n",
      "           1       0.00      0.00      0.00      4363\n",
      "\n",
      "    accuracy                           0.98    206596\n",
      "   macro avg       0.49      0.50      0.49    206596\n",
      "weighted avg       0.96      0.98      0.97    206596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,log.predict(np.array(X_test).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Witch a Logistic model, it pretty much guess every as not fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Random Forest and Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transaction[[\"AMOUNT\",\"TYPE\",\"SOURCE\"]]\n",
    "X = pd.concat([X.AMOUNT,pd.get_dummies(X.drop(\"AMOUNT\",axis=1))],axis =1)\n",
    "y = transaction.Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using 3 features to build Random Forest and Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    202233\n",
      "           1       0.49      0.13      0.21      4363\n",
      "\n",
      "    accuracy                           0.98    206596\n",
      "   macro avg       0.74      0.56      0.60    206596\n",
      "weighted avg       0.97      0.98      0.97    206596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    202233\n",
      "           1       0.59      0.07      0.12      4363\n",
      "\n",
      "    accuracy                           0.98    206596\n",
      "   macro avg       0.79      0.53      0.56    206596\n",
      "weighted avg       0.97      0.98      0.97    206596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the random forest model and gradient decent are not promising as well, with really low recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Base on the EDA, there is a lot of outliers\n",
    "\n",
    "And there is variable in the features can really distinguish between Fraud and not Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction.Fraud = data.Fraud.apply(lambda x: 0 if x== \"0\" else 1)\n",
    "q = transaction.AMOUNT.quantile(0.99)\n",
    "transaction = transaction[transaction[\"AMOUNT\"] < q]\n",
    "transaction.AMOUNT = transaction.AMOUNT/100\n",
    "transaction.drop([\"STATE\"],axis =1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.PHONE_COUNTRY = users.PHONE_COUNTRY.apply(lambda x: x.split(\"||\"))\n",
    "users[\"phone\"] = users.PHONE_COUNTRY.apply(lambda x: len(x))\n",
    "users = pd.merge(users,fraud,how=\"left\",left_on=\"ID\",right_on = \"user_id\")\n",
    "users[\"is_fraud\"] = users.user_id.apply(lambda x:0 if x is np.nan  else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction[\"is_atm\"] =transaction.MERCHANT_CATEGORY.apply(lambda x: 1 if x==\"atm\" else 0)\n",
    "transaction[\"is_GBR\"] = transaction.MERCHANT_COUNTRY.apply(lambda x: 1 if x==\"GBR\" else 0)\n",
    "transaction[\"is_USA\"] = transaction.MERCHANT_COUNTRY.apply(lambda x: 1 if x==\"USA\" else 0)\n",
    "transaction[\"is_manu\"] = transaction.ENTRY_METHOD.apply(lambda x: 1 if x==\"manu\" else 0)\n",
    "transaction[\"is_bank_transfer\"] = transaction.TYPE.apply(lambda x: 1 if x==\"BANK_TRANSFER\" else 0)\n",
    "transaction[\"is_minos\"] = transaction.SOURCE.apply(lambda x: 1 if x==\"MINOS\" else 0)\n",
    "users[\"is_kyc_none\"] = users.KYC.apply(lambda x: 1 if x==\"NONE\" else 0)\n",
    "users[\"is_4\"] =users.phone.apply(lambda x: 1 if x>=4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "need1 = transaction[[\"AMOUNT\",\"USER_ID\",\"is_atm\",\"is_GBR\",\"is_manu\",\"is_bank_transfer\",\"is_minos\",\"Fraud\",\"is_USA\"]]\n",
    "need2 = users[[\"ID\",\"phone\",\"is_kyc_none\",\"is_4\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.merge(need1,need2,how = \"left\",left_on=\"USER_ID\",right_on =\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMOUNT', 'USER_ID', 'is_atm', 'is_GBR', 'is_manu', 'is_bank_transfer',\n",
       "       'is_minos', 'Fraud', 'is_USA', 'ID', 'phone', 'is_kyc_none', 'is_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just want to keep 1 user id and get the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.groupby(\"USER_ID\").median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop([\"USER_ID\",\"Fraud\"],axis =1)\n",
    "y = final_data[\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(1000)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      2316\n",
      "         1.0       0.80      0.59      0.68        90\n",
      "\n",
      "    accuracy                           0.98      2406\n",
      "   macro avg       0.89      0.79      0.83      2406\n",
      "weighted avg       0.98      0.98      0.98      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.01,n_estimators=1000)\n",
    "gb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2316\n",
      "         1.0       0.81      0.63      0.71        90\n",
      "\n",
      "    accuracy                           0.98      2406\n",
      "   macro avg       0.90      0.81      0.85      2406\n",
      "weighted avg       0.98      0.98      0.98      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "really huge improvement from the previous models. Gradient Boost Seem to be the Best as well\n",
    "<BR>\n",
    "Recall is at 52%\n",
    "<BR>\n",
    "Precision is at 79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(X.columns,gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the feature importance graph, seems like some of the features is not that helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_feature = final_data.drop([\"USER_ID\",\"is_4\",\"is_kyc_none\",\"is_USA\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduce_feature.drop([\"Fraud\"],axis =1)\n",
    "y = reduce_feature[\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2316\n",
      "         1.0       0.83      0.63      0.72        90\n",
      "\n",
      "    accuracy                           0.98      2406\n",
      "   macro avg       0.91      0.81      0.85      2406\n",
      "weighted avg       0.98      0.98      0.98      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.01,n_estimators=700)\n",
    "gb.fit(X_train,y_train)\n",
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reducing features incease the precisoin but lower the recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using mean after groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.merge(need1,need2,how = \"left\",left_on=\"USER_ID\",right_on =\"ID\")\n",
    "final_data = final_data.groupby(\"USER_ID\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop([\"USER_ID\",\"Fraud\"],axis =1)\n",
    "y = final_data[\"Fraud\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=20,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3859\n",
      "         1.0       0.79      0.69      0.74       150\n",
      "\n",
      "    accuracy                           0.98      4009\n",
      "   macro avg       0.89      0.84      0.86      4009\n",
      "weighted avg       0.98      0.98      0.98      4009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.01,n_estimators=1000)\n",
    "gb.fit(X_train,y_train)\n",
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try smote and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95      2316\n",
      "         1.0       0.27      0.91      0.41        90\n",
      "\n",
      "    accuracy                           0.90      2406\n",
      "   macro avg       0.63      0.91      0.68      2406\n",
      "weighted avg       0.97      0.90      0.93      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1,n_estimators=700)\n",
    "gb.fit(X_train_res,y_train_res)\n",
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5402\n",
      "         1.0       1.00      1.00      1.00      5402\n",
      "\n",
      "    accuracy                           1.00     10804\n",
      "   macro avg       1.00      1.00      1.00     10804\n",
      "weighted avg       1.00      1.00      1.00     10804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_res,gb.predict(X_train_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RandomUnderSampler(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = ds.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95      2316\n",
      "         1.0       0.27      0.91      0.41        90\n",
      "\n",
      "    accuracy                           0.90      2406\n",
      "   macro avg       0.63      0.91      0.68      2406\n",
      "weighted avg       0.97      0.90      0.93      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1,n_estimators=700)\n",
    "gb.fit(X_train_res,y_train_res)\n",
    "print(classification_report(y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       209\n",
      "         1.0       1.00      0.99      1.00       209\n",
      "\n",
      "    accuracy                           1.00       418\n",
      "   macro avg       1.00      1.00      1.00       418\n",
      "weighted avg       1.00      1.00      1.00       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_res,gb.predict(X_train_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like it's overfitting when using both over sampling and down sampling, but the difference is way too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train.values,y_train.values)\n",
    "dtest = xgb.DMatrix(X_test.values,y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 6, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'rmse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['eval_metric'] = ['rmse', 'ams@0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.176718\teval-ams@0:8.38399\ttrain-rmse:0.162292\ttrain-ams@0:17.7234\n",
      "[1]\teval-rmse:0.141213\teval-ams@0:8.51862\ttrain-rmse:0.111838\ttrain-ams@0:20.6388\n",
      "[2]\teval-rmse:0.136097\teval-ams@0:8.64731\ttrain-rmse:0.096374\ttrain-ams@0:22.789\n",
      "[3]\teval-rmse:0.135661\teval-ams@0:8.91555\ttrain-rmse:0.088294\ttrain-ams@0:23.883\n",
      "[4]\teval-rmse:0.136409\teval-ams@0:8.8646\ttrain-rmse:0.082742\ttrain-ams@0:24.3841\n",
      "[5]\teval-rmse:0.13872\teval-ams@0:8.49779\ttrain-rmse:0.078551\ttrain-ams@0:25.2686\n",
      "[6]\teval-rmse:0.139624\teval-ams@0:8.38399\ttrain-rmse:0.071946\ttrain-ams@0:26.3085\n",
      "[7]\teval-rmse:0.14025\teval-ams@0:8.56149\ttrain-rmse:0.067274\ttrain-ams@0:26.7186\n",
      "[8]\teval-rmse:0.142527\teval-ams@0:8.22142\ttrain-rmse:0.063588\ttrain-ams@0:27.6296\n",
      "[9]\teval-rmse:0.142595\teval-ams@0:8.18549\ttrain-rmse:0.060074\ttrain-ams@0:28.3805\n"
     ]
    }
   ],
   "source": [
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bst = pd.DataFrame()\n",
    "df_bst[\"bst\"] = bst.predict(dtest)\n",
    "df_bst[\"predict\"] =df_bst[\"bst\"].apply(lambda x : 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      2316\n",
      "         1.0       0.67      0.61      0.64        90\n",
      "\n",
      "    accuracy                           0.97      2406\n",
      "   macro avg       0.83      0.80      0.81      2406\n",
      "weighted avg       0.97      0.97      0.97      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,df_bst[\"predict\"] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    " learning_rate =0.1,reg_alpha=0.2,n_estimators=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=700, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0.2, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2316\n",
      "         1.0       0.78      0.64      0.71        90\n",
      "\n",
      "    accuracy                           0.98      2406\n",
      "   macro avg       0.89      0.82      0.85      2406\n",
      "weighted avg       0.98      0.98      0.98      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,xgb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems groupby mean is the best, perform a grid search on the hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
